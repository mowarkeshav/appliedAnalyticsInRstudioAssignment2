{
  "hash": "acf1c3b16c41d541c8e13d9d10636671",
  "result": {
    "markdown": "---\ntitle: \"Keshav's R Journal\"\nauthor: \"Keshav Mowar\"\nformat: html\ntitle-block-banner: true\ntitle-block-banner-color: \"white\"\ntitle-block-categories: true\n---\n\n\n# Date:-2nd February 2024\n# Time:-11:23 PM\n## Trying out some R code from the lab videos\n\nSince R is a scripting language and I have pretty much gotten used to compiled languages it was a little difficult getting used to running separate lines of code and directing it to the console to get the output.\n\nFor now I have tried below lines of code just to get myself used to the console:-\n\n\n::: {.cell}\n\n```{.r .cell-code}\na <- 5\nb <- 6\nz <- a + b\nz <- z + 11\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 22\n```\n:::\n:::\n\n\n\n# Date:-3rd February 2024\n# Time:-10:04 PM\n## Attempting to code a calculator in R\n\n### I tried making a simple calculator using R but failed miserably. I borrowed some code from <https://www.geeksforgeeks.org/taking-input-from-user-in-r-programming/>\n\nI got a warning message when I tried to convert my input from string to a number\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#taking the below code from this URL https://www.geeksforgeeks.org/taking-input-from-user-in-r-programming/\n\nvar <- readline()\n```\n\n```{.r .cell-code}\nvar <- as.integer(var)\nvar\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA\n```\n:::\n\n```{.r .cell-code}\n#building on above code to create a simple calculator\n\na <- readline()\n```\n\n```{.r .cell-code}\na <- as.integer(var)\na\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] NA\n```\n:::\n\n```{.r .cell-code}\nb <- readline()\n```\n\n```{.r .cell-code}\nb\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"\"\n```\n:::\n\n```{.r .cell-code}\nb <- as.integer(var)\nmethod_calc <- readline()\n```\n\n```{.r .cell-code}\nif(method_calc==\"add\"){y <- a+b}\n```\n:::\n\n\n##### unfortunately my attempt to build a calculator has to be postponed as i might have to learn the use of functions and if else statements before attempting that. I will try it very soon.\n\n# Date:-8th February 2024\n# Time:-9:31 AM\n## Attempting to install libraries inside Quarto in order to run the Assignment code\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#installing the required packages. these are the packages I used in assignment 1 as well\n\n#| label: load-packages\n#| warning: true\n#| echo: true\nlibrary(readr)\nlibrary(scales)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'scales'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:readr':\n\n    col_factor\n```\n:::\n\n```{.r .cell-code}\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(RColorBrewer)\n#commenting these out as they are causing error ---install.packages(\"tidyverse\")\n#commenting these out as they are causing error ---install.packages(\"ggplot2\")\n```\n:::\n\n\nThe libraries which are included here help in data visualization like creating bar plots, scatter plots and bar graphs etc.\n\nNow we will see how to utilize these libraries for my data set and come up with some beautiful pie charts and bar graphs. A few of these libraries are used for plotting an the library called \"RColorBrewer\" is used for creating nice color palettes which then can be used for your graphs. I like this feature.\n\n# Date:-20th February 2024\n# Time:-6:44 PM\n## Attempting to install libraries inside Quarto in order to run the Assignment code\n\n##### Initially I was getting an error when trying to use the install function. I asked copilot for the reason of this error\n\n#### Missing Repository Configuration:\n\nWhen you run install.packages(\"tidyverse\"), R needs to know where to find the package. By default, it tries to connect to CRAN, but you need to specify a mirror. To fix this, explicitly set the CRAN mirror by using the repos argument in the install.packages() function. For example: install.packages(\"tidyverse\", repos = \"[http://cran.us.r-project.org\")](http://cran.us.r-project.org\"))\n\n##### So to sort this issue I replaced the original install function with the example given above and now the functions seem to be working.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#installing the required packages. these are the packages I used in assignment 1 as well\n\n#| label: load-packages\n#| warning: true\n#| echo: true\nlibrary(readr)\nlibrary(scales)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(RColorBrewer)\ninstall.packages(\"tidyverse\", repos = \"http://cran.us.r-project.org\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\npackage 'tidyverse' successfully unpacked and MD5 sums checked\n\nThe downloaded binary packages are in\n\tC:\\Users\\Keshav\\AppData\\Local\\Temp\\RtmpYrl8Cr\\downloaded_packages\n```\n:::\n\n```{.r .cell-code}\ninstall.packages(\"ggplot2\", repos = \"http://cran.us.r-project.org\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' is in use and will not be installed\n```\n:::\n:::\n\n\n\n\n# Date:-21st February 2024\n# Time:-5:00 PM\n## Today I am running my code for the assignment 1 dataset.\n\nThis includes multiple bar plots and pie charts showcasing different aspects of the dataset.\n\n#### Now lets try to read the a dataset from a tsv file. These kinds of files have table separated values. This particular dataset is purely categorical data and it has divided website URLS into different categories like Primary Category and Secondary Category.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(50)\n\n# source for the below code https://readr.tidyverse.org/reference/read_delim.html\n\n#I noticed that the readtsv function has an option called \"lazy\" which helps reducing some extra configuration from the developer\n\ncybersecdata1 <- readr::read_tsv('classification.tsv', col_names = TRUE,lazy=TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 26909 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (4): Primary Category, Secondary Category, Title, URL\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\n# I am trying out sampling on this dataset just to see how the values are selected. I am taking only 500 records for this dataset\n\n# source for the below code https://www.digitalocean.com/community/tutorials/sample-in-r\n\ncybersecdata1_sampled <- sample(1:nrow(cybersecdata1), 500)\n\n#after the code is sampled\n\ncybersecdata1_final <- cybersecdata1[cybersecdata1_sampled,]\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat <- vroom(...)\n  problems(dat)\n```\n:::\n\n```{.r .cell-code}\ncybersecdata1_final\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 500 × 4\n   `Primary Category`           `Secondary Category`               Title   URL  \n   <chr>                        <chr>                              <chr>   <chr>\n 1 Government, Law & Politics   European Parliament Elections 2009 Animal… http…\n 2 Government, Law & Politics   Credit Crunch                      Debt o… http…\n 3 Medicine & Health            Conditions and Diseases            Everym… http…\n 4 Arts & Humanities            Geography                          Go-Geo… http…\n 5 Arts & Humanities            Local History                      GELLIG… http…\n 6 Government, Law & Politics   Credit Crunch                      Davent… http…\n 7 Digital Society              Blogs                              Histor… http…\n 8 Arts & Humanities            Live Art                           London… http…\n 9 Business, Economy & Industry Credit Crunch                      London… http…\n10 Society & Culture            Sports and Recreation              Wenloc… http…\n# ℹ 490 more rows\n```\n:::\n\n```{.r .cell-code}\n#Next I group the dataset by the Primary Category column name as it will give an interesting insight. Primary Categories basically show which kind of industries or domains a website belongs to \n\n# source for the below code https://www.linkedin.com/pulse/usage-groupby-dplyr-r-tuhin-tapadar/\n\ngroup_cybersecdata1 <- cybersecdata1_final %>% group_by(`Primary Category`)\n\n#After grouping , I also count the number of times a particular category comes up by using the name_count variable. I also summarize the whole output to get a brief detail on how the tibble looks\n\ngroup_cybersecdata1_sum <- summarise(group_cybersecdata1, name_count = n())\n\n#I used below code to order the tibble in decreasing order so that we can see which category had the most websites. The reason for doing this is to understand the adaptation of web technology by different kinds of industries.\n\n#https://bookdown.org/ndphillips/YaRrr/order-sorting-data.html\n\ngroup_cybersecdata1_ordered <- group_cybersecdata1_sum[order(group_cybersecdata1_sum$name_count, decreasing = TRUE),]\n\n#After ordering I decide to take the top 7 categories which come up. The reason for doing this is because they are the most populated categories and it makes it easier to a statistic visualization of the data.\n\ngroupcybersecdata1_ordered_sample_final <- head(group_cybersecdata1_ordered,7)\n\ngd2 <- groupcybersecdata1_ordered_sample_final\n\n#Once the final datagram is ready which is \"gd2\". I took a decision to draw a pie chart for this dataset. I very well know that pie charts are not really a good way to show data visualization but since this is a non numerical dataset and I am new to R, this is the simplest way I could find to show the dataset.\n\n#To make a simple pie chart , we have to initialize a few variables. One of them will be the content of the pie chart(could be numbers or percentage etc) and the other will be the label of the section.\n\n#name of the primary category\nnamec <- gd2$name_count\n#number of websites comprising this primary category in percentage\nlbls <- gd2$`Primary Category`\n\n#setting the color pallette. \nmyColorPal <- brewer.pal(5, \"Set3\") \n\n#bar graph source code below\n#https://r-graph-gallery.com/131-pie-plot-with-r.html\n#Finaly executing the pie chart\n\npie(namec,labels = paste(lbls, \"\\n\", percent(namec / sum(namec))),col=myColorPal)\n```\n\n::: {.cell-output-display}\n![](KeshavRDiary_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n# Date:-25th February\n#Time:-10:33 PM\n## Attempting the work on my second dataset which I used in my assignment 1.\n\n###Dataset:- https://datadrivensecurity.info/blog/pages/dds-dataset-collection.html\n\n#### Lets talk about this dataset a little bit. The data which is shown here is taken from several honeypot servers residing in different geographical regions. Honeypot servers are usually operated by companies entice hackers and threat actors to attack their server.Keeping in mind that the threat actor might think that the server is vulnerable but in reality it is just a way to threat actors and analyze their approach to prevent a real cyber attack.\n#### Hence honeypot servers are incredibly useful for cyber industry and cyber defense in general. One thing honeypot servers do is that they generate a lot of data.Only because there are so many data transmissions happening. This data definitely could give us valuable insights.\n##### The data is depicted in a nice uniform format. The ip addresses are converted to long format to make it easier to read and operate. Other columns include source and destination server region names. Let see what how we can create a few visualizations using this data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#I have taken this dataset to showcase some of the data transmission which happens on honeypot servers and get some insights \n\n#the second dataset is taken from https://datadrivensecurity.info/blog/pages/dds-dataset-collection.html\n\n\n\n#reading csv\ncybersecdata2 <- read.csv(\"marx.csv\")\n\n#summary and head command just to get a sense of data\nsummary(cybersecdata2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   datetime             host                src               proto          \n Length:451581      Length:451581      Min.   :1.678e+07   Length:451581     \n Class :character   Class :character   1st Qu.:1.169e+09   Class :character  \n Mode  :character   Mode  :character   Median :2.031e+09   Mode  :character  \n                                       Mean   :2.155e+09                     \n                                       3rd Qu.:3.165e+09                     \n                                       Max.   :3.758e+09                     \n                                                                             \n      type             spt             dpt       \n Min.   : 0.0     Min.   :    0   Min.   :    0  \n 1st Qu.: 8.0     1st Qu.: 6000   1st Qu.:  445  \n Median : 8.0     Median : 6000   Median : 1433  \n Mean   : 7.5     Mean   :18685   Mean   : 6684  \n 3rd Qu.: 8.0     3rd Qu.:33461   3rd Qu.: 3389  \n Max.   :13.0     Max.   :65535   Max.   :65500  \n NA's   :406770   NA's   :44811   NA's   :44811  \n```\n:::\n\n```{.r .cell-code}\nhead(cybersecdata2,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n              datetime              host        src proto type   spt  dpt\n1  2013-03-03 21:53:59    groucho-oregon 1032051418   TCP   NA  6000 1433\n2  2013-03-03 21:57:01    groucho-oregon 1347834426   UDP   NA  5270 5060\n3  2013-03-03 21:58:10    groucho-oregon 2947856490   TCP   NA  2489 1080\n4  2013-03-03 21:58:09   groucho-us-east  841842716   UDP   NA 43235 1900\n5  2013-03-03 21:58:20 groucho-singapore 3587648279   TCP   NA 56577   80\n6  2013-03-03 21:58:41     groucho-tokyo 3323217250   TCP   NA 32628 2323\n7  2013-03-03 21:59:36    groucho-oregon 3730416887   TCP   NA  6000 1433\n8  2013-03-03 22:07:05 groucho-singapore 3738622573   TCP   NA  6000 3306\n9  2013-03-03 22:12:02    groucho-oregon 3683919430   TCP   NA  6000 1433\n10 2013-03-03 22:14:19 groucho-singapore 1007884304   TCP   NA  6000 1433\n```\n:::\n\n```{.r .cell-code}\n#The date format is a bit weird so I decided to make it simpler.\n\ncybersecdata2$datetime<- as.Date(cybersecdata2$datetime, format = \"%Y-%m-%d\")\n\n#dataset after changing date format\n\nhead(cybersecdata2,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     datetime              host        src proto type   spt  dpt\n1  2013-03-03    groucho-oregon 1032051418   TCP   NA  6000 1433\n2  2013-03-03    groucho-oregon 1347834426   UDP   NA  5270 5060\n3  2013-03-03    groucho-oregon 2947856490   TCP   NA  2489 1080\n4  2013-03-03   groucho-us-east  841842716   UDP   NA 43235 1900\n5  2013-03-03 groucho-singapore 3587648279   TCP   NA 56577   80\n6  2013-03-03     groucho-tokyo 3323217250   TCP   NA 32628 2323\n7  2013-03-03    groucho-oregon 3730416887   TCP   NA  6000 1433\n8  2013-03-03 groucho-singapore 3738622573   TCP   NA  6000 3306\n9  2013-03-03    groucho-oregon 3683919430   TCP   NA  6000 1433\n10 2013-03-03 groucho-singapore 1007884304   TCP   NA  6000 1433\n```\n:::\n\n```{.r .cell-code}\n#lets sample the data to get fewer records\ncybersecdata2_sampled<- sample(1:nrow(cybersecdata2), 5000)\ncybersecdata2_final <- cybersecdata2[cybersecdata2_sampled,]\nhead(cybersecdata2_final,10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         datetime              host        src proto type   spt   dpt\n197913 2013-06-05     groucho-tokyo 3223748177   TCP   NA  1967   445\n447449 2013-09-06      zeppo-norcal 3736745009   TCP   NA  6000  8080\n313227 2013-07-24     groucho-tokyo   45792730   UDP   NA 10100  2193\n422949 2013-08-27 groucho-singapore 1033063135   TCP   NA  6000  3306\n66963  2013-04-08   groucho-us-east 1914917414   UDP   NA 14702 54521\n138951 2013-05-10     groucho-tokyo 2992298268   TCP   NA  3441   445\n384370 2013-08-18        groucho-sa 1017973655   TCP   NA  6000  7777\n93426  2013-04-20        groucho-eu 2953454577   TCP   NA 27407  9943\n336694 2013-07-30 groucho-singapore 1313866355   TCP   NA  3901    23\n272999 2013-07-09 groucho-singapore 3417478163  ICMP    8    NA    NA\n```\n:::\n\n```{.r .cell-code}\n#grouping the hosts by region and taking their counts.for this analysis I decided to group servers by their region. this will tell us how many data transmissions happened in which region.\n\nhosts_groupby <- cybersecdata2_final %>% group_by(host)\nhosts_sum <- summarise(hosts_groupby, name_count = n())\n\n#plotting a bar plot for showcasing server location and the number of servers in each location\n\nggplot(hosts_sum, aes(x = hosts_sum$host, y = hosts_sum$name_count)) +\n  geom_bar(stat = \"identity\", fill = \"purple\") +  # Bar plot with identity statistic\n  labs(x = \"Geographical region of Host servers\", y = \"Number of Hosts\") +  # Labels for axes\n  ggtitle(\"Bar Plot of regional Honeypot hosts vs. Number of hosts in particular region\") +  # Title for the plot\n  theme_minimal()  \n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Use of `hosts_sum$host` is discouraged.\nℹ Use `host` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Use of `hosts_sum$name_count` is discouraged.\nℹ Use `name_count` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](KeshavRDiary_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#below visualizations will show simple freququncy of data transmission in terms of ports and protocols. for example which protocol was high frequency etc.\n#plotting a histogram to show the relation between source port number ranges and their values\nhist(cybersecdata2_final$spt, \n     main = \"Frequency of source ports probed in the honeypot servers\",\n     xlab = \"Port Number Range\",\n     border = \"purple\", \n     col = \"orange\",)\n```\n\n::: {.cell-output-display}\n![](KeshavRDiary_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#plotting a histogram to show the relation between destination port number ranges and their values\nhist(cybersecdata2_final$dpt, \n     main = \"Frequency of destination ports probed in the honeypot servers\",\n     xlab = \"Port Number Range\",\n     border = \"pink\", \n     col = \"green\",)\n```\n\n::: {.cell-output-display}\n![](KeshavRDiary_files/figure-html/unnamed-chunk-6-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#now I am grouping different protocols and try to show their percentage share in the data collected using both a bar plot and a  pie chart\n#PLEASE NOTE THAT I AM NOT TAKING SAMPLED DATA HERE. I AM RUNNING THIS ON THE ORIGINAL DATASET.\nproto_groupby <- cybersecdata2 %>% group_by(proto)\nproto_sum <- summarise(proto_groupby, num_proto = n())\n\n#this is the bar plot showing the freuqncy of different 3 protocols\nggplot(proto_sum, aes(x = proto_sum$proto, y = proto_sum$num_proto)) +\n  geom_bar(stat = \"identity\", fill = \"yellow\") +  # Bar plot with identity statistic\n  labs(x = \"Name of protocols\", y = \"Frequency of occurence\") +  # Labels for axes\n  ggtitle(\"Protocols observed vs. frequency of them occuring\") +  # Title for the plot\n  theme_minimal()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Use of `proto_sum$proto` is discouraged.\nℹ Use `proto` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Use of `proto_sum$num_proto` is discouraged.\nℹ Use `num_proto` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](KeshavRDiary_files/figure-html/unnamed-chunk-6-4.png){width=672}\n:::\n\n```{.r .cell-code}\n#plotting a pie chart for the above scenario\nfrequency_of_proto <- proto_sum$num_proto\nproto_lbls <- proto_sum$proto\nmyColorPal2 <- brewer.pal(5, \"Set3\")\npie(frequency_of_proto, labels = paste(proto_lbls, \"\\n\", percent(frequency_of_proto / sum(frequency_of_proto))), col = myColorPal2)\n```\n\n::: {.cell-output-display}\n![](KeshavRDiary_files/figure-html/unnamed-chunk-6-5.png){width=672}\n:::\n:::\n\n# Date:-6th March 2024\n# Time:-5:20 PM\n## Learning how to add images to quarto document\n\nI wanted to learn how to add images easily in Markdown and I found the below website really helpful. All I needed to remember was to put the image file in my working directory If I am trying to avoid writing the full path of the file.\n\nhttps://quarto.org/docs/authoring/figures.html\n\n![Adding Images for the first time](addingimages.png)\n\n\n\n# Date:-7th March 2024\n\n# Time:-2:30 PM\n\n## Made a new repository in github for assignment 3\n\nFor today it is just a sample text file commit. Later throughout assignment 3 I will be pushing whatever code I will be writing.\n\n![Github First Ever Commit](gitcode.png)\n\n\n\n",
    "supporting": [
      "KeshavRDiary_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}